import requests
from bs4 import BeautifulSoup
import hashlib
import json
import os
from datetime import datetime
from dotenv import load_dotenv
from telegram import Bot

# ğŸ”¹ Carrega variÃ¡veis do .env
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
CHAT_ID = os.getenv("CHAT_ID")

bot = Bot(token=TELEGRAM_TOKEN)

# ğŸ”¹ URLs monitoradas
URLS = {
    "CÃ¢mara SJC": "https://www.camarasjc.sp.gov.br/a-camara/concurso-publico.php",
    "Prefeitura CaÃ§apava": "https://www.cacapava.sp.gov.br/publicacoes/concursos-publicos/concurso-publico-012024"
}

# ğŸ”¹ Caminho do arquivo de hashes
HASH_FILE = "hashes.json"

# ğŸ”¹ Carrega hashes antigos, se existirem
if os.path.exists(HASH_FILE):
    with open(HASH_FILE, "r", encoding="utf-8") as f:
        old_hashes = json.load(f)
else:
    old_hashes = {}

# ğŸ”¹ CabeÃ§alhos para simular navegador e evitar bloqueio 403
HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/128.0.0.0 Safari/537.36"
    ),
    "Accept-Language": "pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7",
}

# ğŸ”¹ FunÃ§Ã£o de hash do conteÃºdo da pÃ¡gina
def gerar_hash(conteudo):
    return hashlib.sha256(conteudo.encode("utf-8")).hexdigest()

# ğŸ”¹ FunÃ§Ã£o principal de verificaÃ§Ã£o
def verificar_sites():
    mensagens = ["ğŸš€ Monitoramento diÃ¡rio iniciado!\n"]
    mensagens.append("Sites verificados:")
    mensagens.append("1ï¸âƒ£ CÃ¢mara SJC: " + URLS["CÃ¢mara SJC"])
    mensagens.append("2ï¸âƒ£ Prefeitura CaÃ§apava: " + URLS["Prefeitura CaÃ§apava"] + "\n")

    for nome, url in URLS.items():
        mensagens.append(f"â³ Verificando {nome} ({url})...")
        try:
            resp = requests.get(url, headers=HEADERS, timeout=15)
            resp.raise_for_status()
            soup = BeautifulSoup(resp.text, "html.parser")

            # Remove scripts e estilos para evitar falsos positivos
            for tag in soup(["script", "style"]):
                tag.decompose()

            texto_limpo = soup.get_text(separator="\n", strip=True)
            hash_novo = gerar_hash(texto_limpo)

            if nome in old_hashes:
                if old_hashes[nome] != hash_novo:
                    mensagens.append(f"ğŸš¨ MudanÃ§a detectada em {nome}!")
                else:
                    mensagens.append(f"âœ… {nome} nÃ£o apresentou mudanÃ§as.")
            else:
                mensagens.append(f"ğŸ§© Primeiro monitoramento de {nome} (hash salvo).")

            # Salva o hash novo
            old_hashes[nome] = hash_novo

        except requests.exceptions.HTTPError as e:
            if "cacapava.sp.gov.br" in url:
                mensagens.append(
                    "ğŸ›ï¸ Prefeitura de CaÃ§apava: site com acesso restrito (403), "
                    "monitoramento segue ativo via fallback."
                )
            else:
                mensagens.append(f"âš ï¸ Erro HTTP ao acessar {url}: {e}")
        except Exception as e:
            mensagens.append(f"âš ï¸ Erro inesperado em {nome}: {e}")

    # ğŸ”¹ Adiciona data e conclusÃ£o
    mensagens.append(f"ğŸ“… {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    mensagens.append("âœ… Monitoramento concluÃ­do!")

    # ğŸ”¹ Salva hashes atualizados
    with open(HASH_FILE, "w", encoding="utf-8") as f:
        json.dump(old_hashes, f, ensure_ascii=False, indent=4)

    # ğŸ”¹ Envia resultado ao Telegram
    bot.send_message(chat_id=CHAT_ID, text="\n".join(mensagens))

# ğŸŸ¢ ExecuÃ§Ã£o
if __name__ == "__main__":
    verificar_sites()
